{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from https://github.com/firascherif/ABSA-BERT-pair/blob/master/generate/data_utils_sentihood.py\n",
    "\n",
    "# Reference: https://github.com/liufly/delayed-memory-update-entnet\n",
    "\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import json\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import xml.etree.ElementTree\n",
    "\n",
    "# import nltk\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_task(data_dir, aspect2idx):\n",
    "    in_file = os.path.join(data_dir, 'sentihood-train.json')\n",
    "    train = parse_sentihood_json(in_file)\n",
    "    in_file = os.path.join(data_dir, 'sentihood-dev.json')\n",
    "    dev = parse_sentihood_json(in_file)\n",
    "    in_file = os.path.join(data_dir, 'sentihood-test.json')\n",
    "    test = parse_sentihood_json(in_file)\n",
    "\n",
    "    train = convert_input(train, aspect2idx)\n",
    "    train_aspect_idx = get_aspect_idx(train, aspect2idx)\n",
    "    train = tokenize(train)\n",
    "    dev = convert_input(dev, aspect2idx)\n",
    "    dev_aspect_idx = get_aspect_idx(dev, aspect2idx)\n",
    "    dev = tokenize(dev)\n",
    "    test = convert_input(test, aspect2idx)\n",
    "    test_aspect_idx = get_aspect_idx(test, aspect2idx)\n",
    "    test = tokenize(test)\n",
    "\n",
    "    return (train, train_aspect_idx), (dev, dev_aspect_idx), (test, test_aspect_idx)\n",
    "\n",
    "\n",
    "# def get_aspect_idx(data, aspect2idx):\n",
    "#     ret = []\n",
    "#     for _, _, _, aspect, _ in data:\n",
    "#         ret.append(aspect2idx[aspect])\n",
    "#     assert len(data) == len(ret)\n",
    "#     return np.array(ret)\n",
    "\n",
    "\n",
    "def parse_sentihood_json(in_file):\n",
    "    with open(in_file) as f:\n",
    "        data = json.load(f)\n",
    "    ret = []\n",
    "    for d in data:\n",
    "        text = d['text']\n",
    "        sent_id = d['id']\n",
    "        opinions = []\n",
    "        targets = set()\n",
    "        for opinion in d['opinions']:\n",
    "            sentiment = opinion['sentiment']\n",
    "            aspect = opinion['aspect']\n",
    "            target_entity = opinion['target_entity']\n",
    "            targets.add(target_entity)\n",
    "            opinions.append((target_entity, aspect, sentiment))\n",
    "        ret.append((sent_id, text, opinions))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def convert_input(data, all_aspects):\n",
    "    ret = []\n",
    "    for sent_id, text, opinions in data:\n",
    "        for target_entity, aspect, sentiment in opinions:\n",
    "            if aspect not in all_aspects:\n",
    "                continue\n",
    "            ret.append((sent_id, text, target_entity, aspect, sentiment))\n",
    "        assert 'LOCATION1' in text\n",
    "        targets = set(['LOCATION1'])\n",
    "        if 'LOCATION2' in text:\n",
    "            targets.add('LOCATION2')\n",
    "        for target in targets:\n",
    "            aspects = set([a for t, a, _ in opinions if t == target])\n",
    "            none_aspects = [a for a in all_aspects if a not in aspects]\n",
    "            for aspect in none_aspects:\n",
    "                ret.append((sent_id, text, target, aspect, 'None'))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def tokenize(data):\n",
    "    ret = []\n",
    "    for sent_id, text, target_entity, aspect, sentiment in data:\n",
    "        new_text = nltk.word_tokenize(text)\n",
    "        new_aspect = aspect.split('-')\n",
    "        ret.append((sent_id, new_text, target_entity, new_aspect, sentiment))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def all_aspects(data, aspect2idx):\n",
    "    aspect_logits = []\n",
    "    logit = np.zeros(12) #taking care of 0 % 12 \n",
    "    for i , (sent_id, text, target, aspect, sentiment) in enumerate(data, start = 1):\n",
    "        if i % 12 == 0:\n",
    "            aspect_logits.append(logit)\n",
    "            logit = np.zeros(12)\n",
    "        if sentiment != \"None\":\n",
    "            logit[aspect2idx[aspect]] = 1\n",
    "    return aspect_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = parse_sentihood_json(\"sentihood-dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect2idx = {\n",
    "    'general': 0,\n",
    "    'price': 1,\n",
    "    'transit-location': 2,\n",
    "    'safety': 3,\n",
    "    'live' : 4,\n",
    "    'quiet' : 5,\n",
    "    'dining' : 6,\n",
    "    'nightlife' : 7,\n",
    "    'touristy' : 8,\n",
    "    'shopping' : 9,\n",
    "    'green-culture' : 10,\n",
    "    'multicultural' : 11,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322,\n",
       " '( LOCATION1 is the nearest tube station , just about a 4 min walk ) Youre lucky youre going to be studying in London',\n",
       " [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dev = convert_input(dev, aspect2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_aspect_id = get_aspect_idx(converted_dev, aspect2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'multicultural', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'green-culture', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'shopping', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'touristy', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'nightlife', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'dining', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'quiet', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'live', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'safety', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'transit-location', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'price', 'None')\n",
      "(510, \"you'll LOVE LOCATION1\", 'LOCATION1', 'general', 'Positive')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'multicultural', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'green-culture', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'shopping', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'touristy', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'nightlife', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'dining', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'quiet', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'live', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'safety', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'price', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'general', 'None')\n",
      "(507, \"you live around the LOCATION1 station, there's a National Railway route that will take you directly to LOCATION1 in about 30 minutes\", 'LOCATION1', 'transit-location', 'Positive')\n"
     ]
    }
   ],
   "source": [
    "q  = list(reversed(converted_dev1))\n",
    "for i in range(24):\n",
    "    print(q[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aspect_id[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dev.sort(key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11244"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(converted_dev1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11244\n",
      "937.0\n",
      "937\n"
     ]
    }
   ],
   "source": [
    "print(len(converted_dev1))\n",
    "print(len(converted_dev1)/12)\n",
    "print(len(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = all_aspects(converted_dev1, aspect2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 0\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 1\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 2\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 3\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 4\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 5\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 6\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 7\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 8\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 9\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 10\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 11\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 12\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 13\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 14\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 15\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 16\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 17\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 18\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 19\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 20\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 21\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 22\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 23\n"
     ]
    }
   ],
   "source": [
    "k = np.zeros(12)\n",
    "l = 0\n",
    "for i in range(24):\n",
    "    if i%12 ==0 :\n",
    "        k[l] = 1\n",
    "        l += 1\n",
    "    print(k, i)\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
